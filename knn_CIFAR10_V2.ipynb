{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohkharma/kNN_CiFAR10dataset/blob/master/knn_CIFAR10_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O10TAy5kZVQO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "import platform\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# coding: utf-8\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "import platform\n",
        "\n",
        "\n",
        "def load_pickle(f):\n",
        "    version = platform.python_version_tuple()\n",
        "    if version[0] == '2':\n",
        "        return  pickle.load(f)\n",
        "    elif version[0] == '3':\n",
        "        return  pickle.load(f, encoding='latin1')\n",
        "    raise ValueError(\"invalid python version: {}\".format(version))\n",
        "\n",
        "def load_CIFAR_batch(filename):\n",
        "  \"\"\" load single batch of cifar \"\"\"\n",
        "  with open(filename, 'rb') as f:\n",
        "    datadict = load_pickle(f)\n",
        "    X = datadict['data']\n",
        "    Y = datadict['labels']\n",
        "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
        "    Y = np.array(Y)\n",
        "    return X, Y\n",
        "\n",
        "def load_CIFAR10(ROOT):\n",
        "  \"\"\" load all of cifar \"\"\"\n",
        "  xs = []\n",
        "  ys = []\n",
        "  for b in range(1,6):\n",
        "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
        "    X, Y = load_CIFAR_batch(f)\n",
        "    xs.append(X)\n",
        "    ys.append(Y)    \n",
        "  Xtr = np.concatenate(xs)\n",
        "  Ytr = np.concatenate(ys)\n",
        "  del X, Y\n",
        "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
        "  return Xtr, Ytr, Xte, Yte\n"
      ],
      "metadata": {
        "id": "kCJM9dNQZuS0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6E-RYriDZVQT"
      },
      "outputs": [],
      "source": [
        "class KNearestNeighbor(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def train(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "    def predict(self, X, k=1, num_loops=0):\n",
        "        if num_loops == 0:\n",
        "            dists = self.compute_distances(X)\n",
        "        else:\n",
        "            raise ValueError('Invalid value %d for num_loops' % num_loops)\n",
        "        return self.predict_labels(dists, k=k)\n",
        "\n",
        "\n",
        "    def compute_distances(self, X):\n",
        "        num_test = X.shape[0]\n",
        "        num_train = self.X_train.shape[0]\n",
        "        dists = np.zeros((num_test, num_train)) \n",
        "        dists = np.sqrt(np.sum(np.square(self.X_train), axis=1) + np.sum(np.square(X), axis=1)[:, np.newaxis] - 2 * np.dot(X, self.X_train.T))\n",
        "        pass\n",
        "        return dists\n",
        "\n",
        "    def predict_labels(self, dists, k=1):\n",
        "        num_test = dists.shape[0]\n",
        "        y_pred = np.zeros(num_test)\n",
        "        for i in range(num_test):\n",
        "            closest_y = []\n",
        "            sorted_dist = np.argsort(dists[i])\n",
        "            closest_y = list(self.y_train[sorted_dist[0:k]])\n",
        "            pass\n",
        "            y_pred[i]= (np.argmax(np.bincount(closest_y)))\n",
        "            pass\n",
        "        return y_pred\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################################\n",
        "#\n",
        "# Functions for downloading and extracting data-files from the internet.\n",
        "#\n",
        "# Implemented in Python 3.5\n",
        "#\n",
        "########################################################################\n",
        "#\n",
        "# This file is part of the TensorFlow Tutorials available at:\n",
        "#\n",
        "# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
        "#\n",
        "# Published under the MIT License. See the file LICENSE for details.\n",
        "#\n",
        "# Copyright 2016 by Magnus Erik Hvass Pedersen\n",
        "#\n",
        "########################################################################\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import zipfile\n",
        "\n",
        "########################################################################\n",
        "\n",
        "\n",
        "def _print_download_progress(count, block_size, total_size):\n",
        "    \"\"\"\n",
        "    Function used for printing the download progress.\n",
        "    Used as a call-back function in maybe_download_and_extract().\n",
        "    \"\"\"\n",
        "\n",
        "    # Percentage completion.\n",
        "    pct_complete = float(count * block_size) / total_size\n",
        "\n",
        "    # Status-message. Note the \\r which means the line should overwrite itself.\n",
        "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
        "\n",
        "    # Print it.\n",
        "    sys.stdout.write(msg)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "########################################################################\n",
        "\n",
        "\n",
        "def maybe_download_and_extract(url, download_dir):\n",
        "    \"\"\"\n",
        "    Download and extract the data if it doesn't already exist.\n",
        "    Assumes the url is a tar-ball file.\n",
        "\n",
        "    :param url:\n",
        "        Internet URL for the tar-file to download.\n",
        "        Example: \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "\n",
        "    :param download_dir:\n",
        "        Directory where the downloaded file is saved.\n",
        "        Example: \"data/CIFAR-10/\"\n",
        "\n",
        "    :return:\n",
        "        Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    # Filename for saving the file downloaded from the internet.\n",
        "    # Use the filename from the URL and add it to the download_dir.\n",
        "    filename = url.split('/')[-1]\n",
        "    file_path = os.path.join(download_dir, filename)\n",
        "\n",
        "    # Check if the file already exists.\n",
        "    # If it exists then we assume it has also been extracted,\n",
        "    # otherwise we need to download and extract it now.\n",
        "    if not os.path.exists(file_path):\n",
        "        # Check if the download directory exists, otherwise create it.\n",
        "        if not os.path.exists(download_dir):\n",
        "            os.makedirs(download_dir)\n",
        "\n",
        "        # Download the file from the internet.\n",
        "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
        "                                                  filename=file_path,\n",
        "                                                  reporthook=_print_download_progress)\n",
        "\n",
        "        print()\n",
        "        print(\"Download finished. Extracting files.\")\n",
        "\n",
        "        if file_path.endswith(\".zip\"):\n",
        "            # Unpack the zip-file.\n",
        "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(download_dir)\n",
        "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
        "            # Unpack the tar-ball.\n",
        "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(download_dir)\n",
        "\n",
        "        print(\"Done.\")\n",
        "    else:\n",
        "        print(\"Data has apparently already been downloaded and unpacked.\")\n",
        "\n",
        "\n",
        "########################################################################"
      ],
      "metadata": {
        "id": "m_qMKtKOZ4tL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VvWLf2mZVQV"
      },
      "source": [
        "# Downloading the CIFAR-10 dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GYskIIcDZVQY",
        "outputId": "a3898b0b-0abe-44d3-c527-903bf742d0cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Download progress: 100.0%\n",
            "Download finished. Extracting files.\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "download_dir = \"./data\"\n",
        "maybe_download_and_extract(url,download_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0TJTYsNZVQa"
      },
      "source": [
        "# Loading raw files and reading them as training and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZpyUF6jZVQb"
      },
      "outputs": [],
      "source": [
        "cifar10_dir = './data/cifar-10-batches-py'\n",
        "X_train, y_train, X_test, y_test = data_utils.load_CIFAR10(cifar10_dir)\n",
        "\n",
        "# Checking the size of the training and testing data\n",
        "print('Training data shape: ', X_train.shape)\n",
        "print('Training labels shape: ', y_train.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQCevUEmZVQc"
      },
      "source": [
        "# Visualizing dataset samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8m9pN3aZVQc"
      },
      "outputs": [],
      "source": [
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_classes = len(classes)\n",
        "samples_per_class = 7\n",
        "for y, cls in enumerate(classes):\n",
        "    idxs = np.flatnonzero(y_train == y)\n",
        "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt_idx = i * num_classes + y + 1\n",
        "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "        plt.imshow(X_train[idx].astype('uint8'))\n",
        "        plt.axis('off')\n",
        "        if i == 0:\n",
        "            plt.title(cls)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHgyIakJZVQd"
      },
      "source": [
        "# Data subsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePUPaZncZVQe"
      },
      "outputs": [],
      "source": [
        "# Memory error prevention by subsampling data\n",
        "\n",
        "num_training = 10000\n",
        "mask = list(range(num_training))\n",
        "X_train = X_train[mask]\n",
        "y_train = y_train[mask]\n",
        "\n",
        "num_test = 1000\n",
        "mask = list(range(num_test))\n",
        "X_test = X_test[mask]\n",
        "y_test = y_test[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tFbBT7yZVQf"
      },
      "outputs": [],
      "source": [
        "# reshaping data and placing into rows\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "print(X_train.shape, X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP_G2SknZVQg"
      },
      "source": [
        "# Performing K-NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewrC1Q6wZVQg"
      },
      "outputs": [],
      "source": [
        "classifier = KNearestNeighbor()\n",
        "classifier.train(X_train, y_train)\n",
        "dists= classifier.compute_distances(X_test)\n",
        "y_test_pred = classifier.predict_labels(dists, k=5)\n",
        "num_correct = np.sum(y_test_pred == y_test)\n",
        "accuracy = float(num_correct) / num_test\n",
        "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsRVpL--ZVQg"
      },
      "source": [
        "# Cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqapRofVZVQh"
      },
      "source": [
        "performing 5-fold cross validation on k-NN for varying values of k "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrIANqayZVQh"
      },
      "outputs": [],
      "source": [
        "num_folds = 5\n",
        "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
        "\n",
        "X_train_folds = []\n",
        "y_train_folds = []\n",
        "\n",
        "X_train_folds = np.array_split(X_train,num_folds)\n",
        "y_train_folds = np.array_split(y_train,num_folds)\n",
        "k_to_accuracies = {}\n",
        "\n",
        "\n",
        "\n",
        "for k in k_choices:\n",
        "    k_to_accuracies[k] = []\n",
        "    for num_knn in range(0,num_folds):\n",
        "        X_test = X_train_folds[num_knn]\n",
        "        y_test = y_train_folds[num_knn]\n",
        "        X_train = X_train_folds\n",
        "        y_train = y_train_folds\n",
        "        \n",
        "        temp = np.delete(X_train,num_knn,0)\n",
        "        X_train = np.concatenate((temp),axis = 0)\n",
        "        y_train = np.delete(y_train,num_knn,0)\n",
        "        y_train = np.concatenate((y_train),axis = 0)\n",
        "        \n",
        "        classifier = KNearestNeighbor()\n",
        "        classifier.train(X_train, y_train)\n",
        "        dists = classifier.compute_distances(X_test)\n",
        "        y_test_pred = classifier.predict_labels(dists, k)\n",
        "\n",
        "        num_correct = np.sum(y_test_pred == y_test)\n",
        "        accuracy = float(num_correct) / num_test\n",
        "#         print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
        "        k_to_accuracies[k].append(accuracy)\n",
        "\n",
        "\n",
        "print(\"Printing our 5-fold accuracies for varying values of k:\")\n",
        "print()\n",
        "for k in sorted(k_to_accuracies):\n",
        "    for accuracy in k_to_accuracies[k]:\n",
        "        print('k = %d, accuracy = %f' % (k, accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtQJrLlhZVQi"
      },
      "outputs": [],
      "source": [
        "for k in k_choices:\n",
        "    accuracies = k_to_accuracies[k]\n",
        "    plt.scatter([k] * len(accuracies), accuracies)\n",
        "\n",
        "# plot the trend line with error bars that correspond to standard deviation\n",
        "\n",
        "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
        "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
        "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
        "plt.title('Cross-validation on k')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Cross-validation accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg1D16bIZVQj"
      },
      "outputs": [],
      "source": [
        "# Choosing best value of k based on cross-validation results\n",
        "\n",
        "best_k = 10\n",
        "\n",
        "classifier = KNearestNeighbor()\n",
        "classifier.train(X_train, y_train)\n",
        "y_test_pred = classifier.predict(X_test, k=best_k)\n",
        "\n",
        "# Computing and displaying the accuracy for best k found during cross-validation\n",
        "num_correct = np.sum(y_test_pred == y_test)\n",
        "accuracy = float(num_correct) / num_test\n",
        "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKoBnlY0ZVQj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}